{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "209badb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "563f044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for simplifying the piece where the year must be added to all dataframes\n",
    "# Current approach: for loop to import and name all dataframes with a line that adds a year column to each\n",
    "#timespan = [2022,2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,2009,2008,2007,2006,2005,2004]\n",
    "#pricedf_list = {}\n",
    "#for year in timespan:\n",
    "    #pricedf_list[] = \n",
    "    \n",
    "# Refer to advanced OOP class for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1cfe72b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samsung\\AppData\\Local\\Temp\\ipykernel_44096\\2942316513.py:34: DtypeWarning: Columns (1,11,13,14,15,16,17,18,19,20,21,22,23,24,25,26,29,34,36,37,41,43,44,45,46,48,50,56,57,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  p2000 = pd.read_csv('./Data-CSV/Price2000.csv', encoding = 'latin1')\n",
      "C:\\Users\\Samsung\\AppData\\Local\\Temp\\ipykernel_44096\\2942316513.py:40: DtypeWarning: Columns (1,2,4,5,8,9,12,15,19,21,22,23,26,27,29,31,33,36,37,38,40,46,48,49,51,54,55,58,61,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  p1994 = pd.read_csv('./Data-CSV/Price1994.csv', encoding = 'latin1')\n"
     ]
    }
   ],
   "source": [
    "# Reading in price data. Each year contained in a different file. p2022 = Price data for 2022\n",
    "p2022 = pd.read_csv('./Data-CSV/Price2022.csv')\n",
    "p2021 = pd.read_csv('./Data-CSV/Price2021.csv')\n",
    "p2020 = pd.read_csv('./Data-CSV/Price2020.csv')\n",
    "p2019 = pd.read_csv('./Data-CSV/Price2019.csv')\n",
    "p2018 = pd.read_csv('./Data-CSV/Price2018.csv')\n",
    "p2017 = pd.read_csv('./Data-CSV/Price2017.csv')\n",
    "p2016 = pd.read_csv('./Data-CSV/Price2016.csv')\n",
    "p2015 = pd.read_csv('./Data-CSV/Price2015.csv')\n",
    "p2014 = pd.read_csv('./Data-CSV/Price2014.csv')\n",
    "p2013 = pd.read_csv('./Data-CSV/Price2013.csv')\n",
    "p2012 = pd.read_csv('./Data-CSV/Price2012.csv')\n",
    "p2011 = pd.read_csv('./Data-CSV/Price2011.csv')\n",
    "p2010 = pd.read_csv('./Data-CSV/Price2010.csv')\n",
    "p2009 = pd.read_csv('./Data-CSV/Price2009.csv')\n",
    "p2008 = pd.read_csv('./Data-CSV/Price2008.csv')\n",
    "p2007 = pd.read_csv('./Data-CSV/Price2007.csv')\n",
    "p2006 = pd.read_csv('./Data-CSV/Price2006.csv')\n",
    "p2005 = pd.read_csv('./Data-CSV/Price2005.csv')\n",
    "p2004 = pd.read_csv('./Data-CSV/Price2004.csv')\n",
    "\n",
    "# 2003 data is price (cents per kWh) by individual utility company by consumer type\n",
    "# 2002 data has a mean price for each state\n",
    "# Handling separately due to significantly different structure\n",
    "p2003Res = pd.read_csv('./Data-CSV/Price2003_Res.csv')\n",
    "p2003Com = pd.read_csv('./Data-CSV/Price2003_Com.csv')\n",
    "p2003Ind = pd.read_csv('./Data-CSV/Price2003_Ind.csv')\n",
    "p2002Res = pd.read_csv('./Data-CSV/Price2002_Res.csv')\n",
    "p2002Com = pd.read_csv('./Data-CSV/Price2002_Com.csv')\n",
    "p2002Ind = pd.read_csv('./Data-CSV/Price2002_Ind.csv')\n",
    "\n",
    "# 2001 - 1994 data is contained in pdf format, must be converted to csv and structured individually for consistency\n",
    "p2001 = pd.read_csv(\"./Data-CSV/Price2001.csv\", encoding = 'latin1')\n",
    "p2000 = pd.read_csv('./Data-CSV/Price2000.csv', encoding = 'latin1')\n",
    "p1999 = pd.read_csv('./Data-CSV/Price1999.csv', encoding = 'latin1')\n",
    "p1998 = pd.read_csv('./Data-CSV/Price1998.csv', encoding = 'latin1')\n",
    "p1997 = pd.read_csv('./Data-CSV/Price1997.csv', encoding = 'latin1')\n",
    "p1996 = pd.read_csv('./Data-CSV/Price1996.csv', encoding = 'latin1')\n",
    "p1995 = pd.read_csv('./Data-CSV/Price1995.csv', encoding = 'latin1')\n",
    "p1994 = pd.read_csv('./Data-CSV/Price1994.csv', encoding = 'latin1')\n",
    "\n",
    "dfs = [p2022, p2021, p2020, p2019, p2018, p2017, p2016, p2015, p2014, p2013, \n",
    "       p2012, p2011, p2010, p2009, p2008, p2007, p2006, p2005, p2004]\n",
    "dfs2003 = [p2003Res, p2003Ind, p2003Com]\n",
    "dfs2002 = [p2002Res, p2002Com, p2002Ind]\n",
    "\n",
    "state_prices = {}\n",
    "state_pricing = {}\n",
    "\n",
    "# Including both headline and core inflation data. Price is adjusted according to headline while core is used as independent variable\n",
    "# Headline inflation rates\n",
    "headline_inflation = [2.8,2.9,2.3,1.6,2.2,3.4,2.8,1.6,2.3,2.7,3.4,3.2,2.9,3.8,-0.4,1.6,3.2,2.1,1.5,1.6,0.1,1.3,2.1,2.4,1.8,1.2,4.7,8.0]\n",
    "headline_cpi = [100]\n",
    "for x in headline_inflation:\n",
    "    headline_cpi.append(round(((x / 100)+1) * headline_cpi[-1], 4))\n",
    "    \n",
    "# Core inflation rates\n",
    "inflation_rates = [3, 2.6, 2.2, 2.4, 1.9, 2.6, 2.7, 1.9, 1.1, 2.2, 2.2, 2.6, 2.4, 1.8, 1.8, 0.8, 2.2, 1.9, 1.7, 1.6, 2.1, 2.2, 1.8, 2.2, 2.3, 1.6, 5.5, 5.7]\n",
    "core_cpi = [100]\n",
    "for x in inflation_rates:\n",
    "    core_cpi.append(round(((x / 100)+1) * core_cpi[-1], 4))\n",
    "\n",
    "# Creating df to concatenate with 94 - 01 price data\n",
    "headcpi_df = pd.DataFrame(headline_cpi)\n",
    "headcpi_df.rename(columns={0:'CPI'}, inplace = True)\n",
    "cpi_df = pd.DataFrame(core_cpi)\n",
    "cpi_df.rename(columns={0:'Core_CPI'}, inplace = True)\n",
    "timespan = ['2022','2021','2020','2019','2018','2017','2016','2015','2014','2013','2012','2011','2010','2009','2008',\n",
    "            '2007','2006','2005','2004', '2003', '2002', '2001', '2000', '1999', '1998', '1997', '1996', '1995', '1994']\n",
    "headcpi_df['Year'] = timespan[::-1]\n",
    "cpi_df['Year'] = timespan[::-1]\n",
    "headcpi_df.set_index('Year', inplace = True)\n",
    "cpi_df.set_index('Year', inplace = True)\n",
    "\n",
    "# Creating dictionary and list of key values for changing full state names to abbreviated\n",
    "abbrev_dict = {\n",
    "               \"Alabama\": \"AL\",\"Alaska\": \"AK\",\"Arizona\": \"AZ\",\"Arkansas\": \"AR\",\"California\": \"CA\",\"Colorado\": \"CO\",\n",
    "               \"Connecticut\": \"CT\", \"Delaware\": \"DE\",\"Florida\": \"FL\",\"Georgia\": \"GA\",\"Hawaii\": \"HI\",\"Idaho\": \"ID\",\n",
    "               \"Illinois\": \"IL\",\"Indiana\": \"IN\",\"Iowa\": \"IA\", \"Kansas\": \"KS\",\"Kentucky\": \"KY\",\"Louisiana\": \"LA\",\n",
    "               \"Maine\": \"ME\",\"Maryland\": \"MD\",\"Massachusetts\": \"MA\",\"Michigan\": \"MI\",\"Minnesota\": \"MN\",\n",
    "               \"Mississippi\": \"MS\",\"Missouri\": \"MO\",\"Montana\": \"MT\",\"Nebraska\": \"NE\",\"Nevada\": \"NV\",\n",
    "               \"New Hampshire\": \"NH\",\"New Jersey\": \"NJ\",\"New Mexico\": \"NM\", \"New York\": \"NY\",\"North Carolina\": \"NC\",\n",
    "               \"North Dakota\": \"ND\",\"Ohio\": \"OH\",\"Oklahoma\": \"OK\",\"Oregon\": \"OR\",\"Pennsylvania\": \"PA\",\n",
    "               \"Rhode Island\": \"RI\", \"South Carolina\": \"SC\",\"South Dakota\": \"SD\",\"Tennessee\": \"TN\",\"Texas\": \"TX\",\n",
    "               \"Utah\": \"UT\",\"Vermont\": \"VT\",\"Virginia\": \"VA\",\"Washington\": \"WA\", \"West Virginia\": \"WV\",\n",
    "               \"Wisconsin\": \"WI\",\"Wyoming\": \"WY\",\"District of Columbia\": \"DC\",\"U.S. Total\": \"US\",\n",
    "               \"New England\": \"New England\",\"Middle Atlantic\": \"Middle Atlantic\",\n",
    "               \"East North Central\":\"East North Central\",\"West North Central\":\"West North Central\",\n",
    "               \"South Atlantic\":\"South Atlantic\",\"East South Central\":\"East South Central\",\n",
    "               \"West South Central\":\"West South Central\",\"Mountain\":\"Mountain\",\n",
    "               \"Pacific Contiguous\":\"Pacific Contiguous\",\"Pacific Noncontiguous\":\"Pacific Noncontiguous\",\n",
    "               \"US Average\":'US', 'US Total':'US'\n",
    "                }\n",
    "states_for_prices = []\n",
    "for key, value in abbrev_dict.items():\n",
    "    states_for_prices.append(value)\n",
    "states_for_prices = set(states_for_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55ac8b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1994 through 2001 price data is converted from pdf to csv and must each be formatted separately\n",
    "\n",
    "# 1994 - Renaming columns\n",
    "p1994.rename(columns = {p1994.columns[0]:'State', 'Unnamed: 29':'Residential', 'Unnamed: 34':'Commercial', 'Unnamed: 46':'Industrial'}, inplace = True)\n",
    "# Finding and isolating required data\n",
    "#p1994[p1994['State'] == '22                                            Energy Information Administration/ Electric Sales and Revenue 1994']\n",
    "# Isolating required data\n",
    "for_dropping1 = list(range(0,609,1))\n",
    "for_dropping2 = list(range(674,13918,1))\n",
    "p1994.drop(for_dropping1, inplace = True)\n",
    "p1994.drop(for_dropping2, inplace = True)\n",
    "p1994.dropna(axis = 'columns', how = 'all', inplace = True)\n",
    "p1994.drop(columns=['Unnamed: 26', 'Unnamed: 36', 'Unnamed: 53', 'Unnamed: 54', 'Unnamed: 61', 'Unnamed: 62'], inplace = True)\n",
    "p1994.dropna(inplace = True)\n",
    "p1994['Year'] = '1994'\n",
    "p1994.reset_index(drop = True, inplace = True)\n",
    "# Changing datatypes\n",
    "p1994['Residential'] = p1994.Residential.apply(float)\n",
    "p1994['Commercial'] = p1994.Commercial.apply(float)\n",
    "p1994['Industrial'] = p1994.Industrial.apply(float)\n",
    "p1994['State'] = p1994.State.str.replace('.', '')\n",
    "p1994['State'] = p1994.State.apply(str)\n",
    "\n",
    "\n",
    "# 1995 - Renaming columns\n",
    "p1995.rename(columns = {p1995.columns[0]:'State', 'Unnamed: 21':'Residential', 'Unnamed: 27':'Commercial', 'Unnamed: 32':'Industrial'}, inplace = True)\n",
    "# Finding and isolating required data\n",
    "#p1995[p1995['State'] == 'Table 12.    Average Revenue per Kilowatthour by Sector, Census Division, and State, 1995\\n(Cents)']\n",
    "# Isolating required data\n",
    "for_dropping1 = list(range(0,632,1))\n",
    "for_dropping2 = list(range(696,6371,1))\n",
    "p1995.drop(for_dropping1, inplace = True)\n",
    "p1995.drop(for_dropping2, inplace = True)\n",
    "p1995.dropna(axis = 'columns', how = 'all', inplace = True)\n",
    "p1995.drop(columns=['Unnamed: 19', 'Unnamed: 25', 'Unnamed: 31', 'Unnamed: 36', 'Unnamed: 37', 'Unnamed: 40', 'Unnamed: 42'], inplace = True)\n",
    "p1995.dropna(inplace = True)\n",
    "p1995['Year'] = '1995'\n",
    "p1995.reset_index(drop = True, inplace = True)\n",
    "# Changing datatypes\n",
    "p1995['Residential'] = p1995.Residential.apply(float)\n",
    "p1995['Commercial'] = p1995.Commercial.apply(float)\n",
    "p1995['Industrial'] = p1995.Industrial.apply(float)\n",
    "p1995['State'] = p1995.State.str.replace('.', '')\n",
    "p1995['State'] = p1995.State.apply(str)\n",
    "\n",
    "\n",
    "# 1996 - Renaming columns\n",
    "p1996.rename(columns = {p1996.columns[0]:'State', 'Unnamed: 27':'Residential', 'Unnamed: 35':'Commercial', 'Unnamed: 40':'Industrial'}, inplace=True)\n",
    "# Finding and isolating required data\n",
    "#p1996[p1996['State'] == 'Table 12.    Average Revenue per Kilowatthour by Sector, Census Division, and State, 1996\\n(Cents)']\n",
    "# Isolating required data\n",
    "for_dropping1 = list(range(0,631,1))\n",
    "for_dropping2 = list(range(695,6196,1))\n",
    "p1996.drop(for_dropping1, inplace = True)\n",
    "p1996.drop(for_dropping2, inplace = True)\n",
    "p1996.dropna(axis = 'columns', how = 'all', inplace = True)\n",
    "p1996.drop(columns=['Unnamed: 25', 'Unnamed: 33', 'Unnamed: 39', 'Unnamed: 45', 'Unnamed: 48', 'Unnamed: 50'], inplace = True)\n",
    "p1996.dropna(inplace = True)\n",
    "p1996['Year'] = '1996'\n",
    "p1996.reset_index(drop = True, inplace = True)\n",
    "# Changing datatypes\n",
    "p1996['Residential'] = p1996.Residential.apply(float)\n",
    "p1996['Commercial'] = p1996.Commercial.apply(float)\n",
    "p1996['Industrial'] = p1996.Industrial.apply(float)\n",
    "p1996['State'] = p1996.State.str.replace('.', '')\n",
    "p1996['State'] = p1996.State.apply(str)\n",
    "\n",
    "\n",
    "# 1997 - Renaming columns\n",
    "p1997.rename(columns = {p1997.columns[0]:'State', 'Unnamed: 31':'Residential', 'Unnamed: 39':'Commercial', 'Unnamed: 46':'Industrial'}, inplace=True)\n",
    "# Finding and isolating required data\n",
    "#p1997[p1997['State'] == 'Table 12.    Average Revenue per Kilowatthour by Sector, Census Division, and State, 1997\\n(Cents)']\n",
    "# Isolating required data\n",
    "for_dropping1 = list(range(0,728,1))\n",
    "for_dropping2 = list(range(792,6290,1))\n",
    "p1997.drop(for_dropping1, inplace = True)\n",
    "p1997.drop(for_dropping2, inplace = True)\n",
    "p1997.dropna(axis = 'columns', how = 'all', inplace = True)\n",
    "p1997.drop(columns=['Unnamed: 28', 'Unnamed: 36', 'Unnamed: 44', 'Unnamed: 52', 'Unnamed: 53', 'Unnamed: 58', 'Unnamed: 60'], inplace = True)\n",
    "p1997.dropna(inplace = True)\n",
    "p1997['Year'] = '1997'\n",
    "p1997.reset_index(drop = True, inplace = True)\n",
    "# Changing datatypes\n",
    "p1997['Residential'] = p1997.Residential.apply(float)\n",
    "p1997['Commercial'] = p1997.Commercial.apply(float)\n",
    "p1997['Industrial'] = p1997.Industrial.apply(float)\n",
    "p1997['State'] = p1997.State.str.replace('.', '')\n",
    "p1997['State'] = p1997.State.apply(str)\n",
    "\n",
    "\n",
    "# 1998 - Renaming columns\n",
    "p1998.rename(columns = {p1998.columns[0]:'State', 'Unnamed: 31':'Residential', 'Unnamed: 38':'Commercial', 'Unnamed: 46':'Industrial'}, inplace=True)\n",
    "# Finding and isolating required data\n",
    "#p1998[p1998['State'] == 'Table 12.    Average Revenue per Kilowatthour by Sector, Census Division, and State, 1998\\n(Cents)']\n",
    "# Isolating required data\n",
    "for_dropping1 = list(range(0,756,1))\n",
    "for_dropping2 = list(range(820,7192,1))\n",
    "p1998.drop(for_dropping1, inplace = True)\n",
    "p1998.drop(for_dropping2, inplace = True)\n",
    "p1998.dropna(axis = 'columns', how = 'all', inplace = True)\n",
    "p1998.drop(columns=['Unnamed: 30', 'Unnamed: 45', 'Unnamed: 53', 'Unnamed: 54', 'Unnamed: 61', 'Unnamed: 63'], inplace = True)\n",
    "p1998.dropna(inplace = True)\n",
    "p1998['Year'] = '1998'\n",
    "p1998.reset_index(drop = True, inplace = True)\n",
    "# Changing datatypes\n",
    "p1998['Residential'] = p1998.Residential.apply(float)\n",
    "p1998['Commercial'] = p1998.Commercial.apply(float)\n",
    "p1998['Industrial'] = p1998.Industrial.apply(float)\n",
    "p1998['State'] = p1998.State.str.replace('.', '')\n",
    "p1998['State'] = p1998.State.apply(str)\n",
    "\n",
    "\n",
    "# 1999 - Renaming columns\n",
    "p1999.rename(columns = {p1999.columns[0]:'State', 'Unnamed: 26':'Residential', 'Unnamed: 32':'Commercial', 'Unnamed: 38':'Industrial'}, inplace = True)\n",
    "# Finding and isolating required data\n",
    "#p1999[p1999['State'] == '(Cents)']\n",
    "# Isolating required data\n",
    "for_dropping1 = list(range(0,788,1))\n",
    "for_dropping2 = list(range(852,7778,1))\n",
    "p1999.drop(for_dropping1, inplace = True)\n",
    "p1999.drop(for_dropping2, inplace = True)\n",
    "p1999.dropna(axis = 'columns', how = 'all', inplace = True)\n",
    "p1999.drop(columns=['Unnamed: 24', 'Unnamed: 37', 'Unnamed: 43', 'Unnamed: 44', 'Unnamed: 48', 'Unnamed: 49'], inplace = True)\n",
    "p1999.dropna(inplace = True)\n",
    "p1999['Year'] = '1999'\n",
    "p1999.reset_index(drop = True, inplace = True)\n",
    "# Changing datatypes\n",
    "p1999['Residential'] = p1999.Residential.apply(float)\n",
    "p1999['Commercial'] = p1999.Commercial.apply(float)\n",
    "p1999['Industrial'] = p1999.Industrial.apply(float)\n",
    "p1999['State'] = p1999.State.str.replace('.', '')\n",
    "p1999['State'] = p1999.State.apply(str)\n",
    "\n",
    "\n",
    "# 2000 - Renaming columns\n",
    "p2000.rename(columns = {p2000.columns[0]:'State', 'Unnamed: 20':'Residential', 'Unnamed: 29':'Commercial','Unnamed: 38':'Industrial'}, inplace = True)\n",
    "# Finding and isolating required data\n",
    "#p2000[p2000['State'] == '(Cents)']\n",
    "# Isolating required data\n",
    "for_dropping1 = list(range(0,433,1))\n",
    "for_dropping2 = list(range(497,8361,1))\n",
    "p2000.drop(for_dropping1, inplace = True)\n",
    "p2000.drop(for_dropping2, inplace = True)\n",
    "p2000.dropna(axis = 'columns', how = 'all', inplace = True)\n",
    "p2000.drop(columns=['Unnamed: 13', 'Unnamed: 25', 'Unnamed: 33', 'Unnamed: 42', 'Unnamed: 51', 'Unnamed: 53'], inplace = True)\n",
    "p2000.dropna(inplace=True)\n",
    "p2000['Year'] = '2000'\n",
    "p2000.reset_index(drop = True, inplace = True)\n",
    "# Changing datatypes\n",
    "p2000['Residential'] = p2000.Residential.apply(float)\n",
    "p2000['Commercial'] = p2000.Commercial.apply(float)\n",
    "p2000['Industrial'] = p2000.Industrial.apply(float)\n",
    "p2000['State'] = p2000.State.str.replace('.', '')\n",
    "p2000['State'] = p2000.State.apply(str)\n",
    "\n",
    "\n",
    "# 2001 - Renaming columns\n",
    "p2001.rename(columns = {p2001.columns[0]:'State', 'Unnamed: 3':'Residential', 'Unnamed: 4':'Commercial','Unnamed: 8':'Industrial'}, inplace = True)\n",
    "# Finding and isolating required data\n",
    "#p2001[p2001['State'] == 'Table 1d. Average Revenue per Kilowatthour for Bundled and Unbundled Consumers by Sector, Census Division, and State, 2001']\n",
    "# Isolating required data\n",
    "for_dropping1 = list(range(0,398,1))\n",
    "for_dropping2 = list(range(463,13149,1))\n",
    "p2001.drop(for_dropping1, inplace = True)\n",
    "p2001.drop(for_dropping2, inplace = True)\n",
    "p2001.dropna(axis = 'columns', how = 'all', inplace = True)\n",
    "p2001.drop(columns = ['Unnamed: 11', 'Unnamed: 14'], inplace = True)\n",
    "p2001.dropna(inplace = True)\n",
    "p2001['Year'] = '2001'\n",
    "p2001.reset_index(drop = True, inplace = True)\n",
    "# Changing datatypes\n",
    "p2001['Residential'] = p2001.Residential.apply(float)\n",
    "p2001['Commercial'] = p2001.Commercial.apply(float)\n",
    "p2001['Industrial'] = p2001.Industrial.apply(float)\n",
    "p2001['State'] = p2001.State.apply(str)\n",
    "\n",
    "# Combining all 2001 - 1994 dataframes for ease of joining with all years later\n",
    "dfs01_94 = [p1994, p1995, p1996, p1997, p1998, p1999, p2000, p2001]\n",
    "for df in dfs01_94:\n",
    "    df['State'] = df['State'].str.strip()\n",
    "    df.replace({\"State\": abbrev_dict}, inplace = True)\n",
    "\n",
    "dfs01_94 = pd.concat([p1994, p1995, p1996, p1997, p1998, p1999, p2000, p2001])\n",
    "\n",
    "# Creating a dictionary of dataframes for 1994 - 2001 price data\n",
    "dfs01_94_dict = {}\n",
    "for state in states_for_prices:\n",
    "    dfs01_94_dict[state] = dfs01_94[dfs01_94['State'] == state]\n",
    "    dfs01_94_dict[state].set_index('Year', inplace=True)\n",
    "    dfs01_94_dict[state].columns.name = state\n",
    "    dfs01_94_dict[state].drop(columns = 'State', inplace = True)\n",
    "    dfs01_94_dict[state] = pd.concat([dfs01_94_dict[state], headcpi_df.loc[['1994','1995','1996','1997','1998','1999','2000','2001']]], axis=1)\n",
    "    dfs01_94_dict[state]['Residential_adj'] = round(dfs01_94_dict[state]['Residential'] / (dfs01_94_dict[state]['CPI'] / 100), 2)\n",
    "    dfs01_94_dict[state]['Commercial_adj'] = round(dfs01_94_dict[state]['Commercial'] / (dfs01_94_dict[state]['CPI'] / 100), 2)\n",
    "    dfs01_94_dict[state]['Industrial_adj'] = round(dfs01_94_dict[state]['Industrial'] / (dfs01_94_dict[state]['CPI'] / 100), 2)\n",
    "    dfs01_94_dict[state] = pd.concat([dfs01_94_dict[state], cpi_df.loc[['1994','1995','1996','1997','1998','1999','2000','2001']]], axis = 1)\n",
    "\n",
    "# Discarding regional data. Add back once regional data is strucutred to accept it\n",
    "dfs01_94_dict.pop('New England')\n",
    "dfs01_94_dict.pop('Middle Atlantic')\n",
    "dfs01_94_dict.pop('East North Central')\n",
    "dfs01_94_dict.pop('West North Central')\n",
    "dfs01_94_dict.pop('South Atlantic')\n",
    "dfs01_94_dict.pop('East South Central')\n",
    "dfs01_94_dict.pop('West South Central')\n",
    "dfs01_94_dict.pop('Mountain')\n",
    "dfs01_94_dict.pop('Pacific Contiguous')\n",
    "dfs01_94_dict.pop('Pacific Noncontiguous');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e7d17c98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Residential</th>\n",
       "      <th>Commercial</th>\n",
       "      <th>Industrial</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Residential_adj</th>\n",
       "      <th>Commercial_adj</th>\n",
       "      <th>Industrial_adj</th>\n",
       "      <th>Core_CPI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>8.38</td>\n",
       "      <td>7.73</td>\n",
       "      <td>4.77</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>8.38</td>\n",
       "      <td>7.73</td>\n",
       "      <td>4.77</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>8.40</td>\n",
       "      <td>7.69</td>\n",
       "      <td>4.66</td>\n",
       "      <td>102.8000</td>\n",
       "      <td>8.17</td>\n",
       "      <td>7.48</td>\n",
       "      <td>4.53</td>\n",
       "      <td>103.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>8.36</td>\n",
       "      <td>7.64</td>\n",
       "      <td>4.60</td>\n",
       "      <td>105.7812</td>\n",
       "      <td>7.90</td>\n",
       "      <td>7.22</td>\n",
       "      <td>4.35</td>\n",
       "      <td>105.6780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>8.43</td>\n",
       "      <td>7.59</td>\n",
       "      <td>4.53</td>\n",
       "      <td>108.2142</td>\n",
       "      <td>7.79</td>\n",
       "      <td>7.01</td>\n",
       "      <td>4.19</td>\n",
       "      <td>108.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>8.26</td>\n",
       "      <td>7.41</td>\n",
       "      <td>4.48</td>\n",
       "      <td>109.9456</td>\n",
       "      <td>7.51</td>\n",
       "      <td>6.74</td>\n",
       "      <td>4.07</td>\n",
       "      <td>110.5950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>8.16</td>\n",
       "      <td>7.26</td>\n",
       "      <td>4.43</td>\n",
       "      <td>112.3644</td>\n",
       "      <td>7.26</td>\n",
       "      <td>6.46</td>\n",
       "      <td>3.94</td>\n",
       "      <td>112.6963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>8.24</td>\n",
       "      <td>7.43</td>\n",
       "      <td>4.64</td>\n",
       "      <td>116.1848</td>\n",
       "      <td>7.09</td>\n",
       "      <td>6.39</td>\n",
       "      <td>3.99</td>\n",
       "      <td>115.6264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>8.62</td>\n",
       "      <td>7.93</td>\n",
       "      <td>5.04</td>\n",
       "      <td>119.4380</td>\n",
       "      <td>7.22</td>\n",
       "      <td>6.64</td>\n",
       "      <td>4.22</td>\n",
       "      <td>118.7483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Residential  Commercial  Industrial       CPI  Residential_adj  \\\n",
       "Year                                                                   \n",
       "1994         8.38        7.73        4.77  100.0000             8.38   \n",
       "1995         8.40        7.69        4.66  102.8000             8.17   \n",
       "1996         8.36        7.64        4.60  105.7812             7.90   \n",
       "1997         8.43        7.59        4.53  108.2142             7.79   \n",
       "1998         8.26        7.41        4.48  109.9456             7.51   \n",
       "1999         8.16        7.26        4.43  112.3644             7.26   \n",
       "2000         8.24        7.43        4.64  116.1848             7.09   \n",
       "2001         8.62        7.93        5.04  119.4380             7.22   \n",
       "\n",
       "      Commercial_adj  Industrial_adj  Core_CPI  \n",
       "Year                                            \n",
       "1994            7.73            4.77  100.0000  \n",
       "1995            7.48            4.53  103.0000  \n",
       "1996            7.22            4.35  105.6780  \n",
       "1997            7.01            4.19  108.0029  \n",
       "1998            6.74            4.07  110.5950  \n",
       "1999            6.46            3.94  112.6963  \n",
       "2000            6.39            3.99  115.6264  \n",
       "2001            6.64            4.22  118.7483  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "#dfs01_94_dict['US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "63981837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2002 data is imported through 3 csv files, 1 per consumer type\n",
    "\n",
    "# Renaming and organizing according to consumer type\n",
    "for df in dfs2002:\n",
    "    df.rename(columns={df.columns[0]:'State'}, inplace = True)\n",
    "    df.drop(columns=['Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace = True)\n",
    "    df.replace({\"State\": abbrev_dict}, inplace = True)\n",
    "\n",
    "    if df is p2002Res:\n",
    "        df.rename(columns = {'Unnamed: 5': 'Residential'}, inplace = True)\n",
    "        dfResS = df[df['State'].isin(states_for_prices)]\n",
    "        dfResS.drop(columns = 'Residential', inplace = True)\n",
    "        dfResS.reset_index(drop = True, inplace = True)\n",
    "        dfResP = df[df['State'] == ' State Total']\n",
    "        dfResP.reset_index(drop = True, inplace = True)\n",
    "        dfResP.drop(columns = 'State', inplace = True)\n",
    "        dfs2002[0] = pd.concat([dfResS, dfResP], axis = 1)\n",
    "    elif df is p2002Com:\n",
    "        df.rename(columns = {'Unnamed: 5': 'Commercial'}, inplace = True)\n",
    "        dfComS = df[df['State'].isin(states_for_prices)]\n",
    "        dfComS.drop(columns = 'Commercial', inplace = True)\n",
    "        dfComS.reset_index(drop = True, inplace = True)\n",
    "        dfComP = df[df['State'] == ' State Total']\n",
    "        dfComP.reset_index(drop = True, inplace = True)\n",
    "        dfComP.drop(columns = 'State', inplace = True)\n",
    "        dfs2002[1] = pd.concat([dfComS, dfComP], axis = 1)\n",
    "    elif df is p2002Ind:\n",
    "        df.rename(columns = {'Unnamed: 5': 'Industrial'}, inplace = True)\n",
    "        dfIndS = df[df['State'].isin(states_for_prices)]\n",
    "        dfIndS.drop(columns = 'Industrial', inplace = True)\n",
    "        dfIndS.reset_index(drop = True, inplace = True)\n",
    "        dfIndP = df[df['State'] == ' State Total']\n",
    "        dfIndP.reset_index(drop = True, inplace = True)\n",
    "        dfIndP.drop(columns = 'State', inplace = True)\n",
    "        dfs2002[2] = pd.concat([dfIndS, dfIndP], axis = 1)\n",
    "\n",
    "# Changing datatypes and adding inflation adjustments\n",
    "p2002 = dfs2002[0]\n",
    "p2002['Commercial'] = dfs2002[1]['Commercial']\n",
    "p2002['Industrial'] = dfs2002[2]['Industrial']\n",
    "p2002['Year'] = '2002'\n",
    "p2002['Residential'] = p2002.Residential.apply(float)\n",
    "p2002['Commercial'] = p2002.Commercial.apply(float)\n",
    "p2002['Industrial'] = p2002.Industrial.apply(float)\n",
    "usline = {'State': 'US', 'Residential': 0, 'Commercial': 0, 'Industrial': 0, 'Year': '2002'}\n",
    "usline = pd.DataFrame(data = usline, index = [51])\n",
    "usline['Residential'] = round(p2002['Residential'].mean(), 2)\n",
    "usline['Commercial'] = round(p2002['Commercial'].mean(), 2)\n",
    "usline['Industrial'] = round(p2002['Industrial'].mean(), 2)\n",
    "p2002 = pd.concat([p2002, usline])\n",
    "p2002.set_index('Year', inplace = True)\n",
    "p2002['CPI'] = headline_cpi[8]\n",
    "p2002['Residential_adj'] = round(p2002['Residential'] / (p2002['CPI'] / 100), 2)\n",
    "p2002['Commercial_adj'] = round(p2002['Commercial'] / (p2002['CPI'] / 100), 2)\n",
    "p2002['Industrial_adj'] = round(p2002['Industrial'] / (p2002['CPI'] / 100), 2)\n",
    "p2002['Core_CPI'] = core_cpi[8]\n",
    "\n",
    "# creating dictionary of dataframes. State as key.\n",
    "p2002_dict = {}\n",
    "for state in list(p2002['State']):\n",
    "    p2002_dict[state] = p2002[p2002['State'] == state]\n",
    "    p2002_dict[state].drop(columns = 'State', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6137dd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Residential</th>\n",
       "      <th>Commercial</th>\n",
       "      <th>Industrial</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Residential_adj</th>\n",
       "      <th>Commercial_adj</th>\n",
       "      <th>Industrial_adj</th>\n",
       "      <th>Core_CPI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>8.52</td>\n",
       "      <td>7.47</td>\n",
       "      <td>5.19</td>\n",
       "      <td>121.349</td>\n",
       "      <td>7.02</td>\n",
       "      <td>6.16</td>\n",
       "      <td>4.28</td>\n",
       "      <td>121.0045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Residential  Commercial  Industrial      CPI  Residential_adj  \\\n",
       "Year                                                                  \n",
       "2002         8.52        7.47        5.19  121.349             7.02   \n",
       "\n",
       "      Commercial_adj  Industrial_adj  Core_CPI  \n",
       "Year                                            \n",
       "2002            6.16            4.28  121.0045  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2002_dict['US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd222d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizing 2003 Price Data - Data came in 3 csv files by consumer type and was organized by each generator by state\n",
    "\n",
    "#def reading_prices_2003(dflist):\n",
    "for df in dfs2003:\n",
    "    df.drop(columns={df.columns[0]}, inplace = True)\n",
    "    df.rename(columns = {'Unnamed: 1':'State'}, inplace = True)\n",
    "    df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5'], inplace = True)\n",
    "    df.dropna(axis = 'columns', how = 'all', inplace = True)\n",
    "    df.dropna(inplace = True)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    df.drop(0 , axis = 0, inplace = True)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    if df is p2003Res:\n",
    "        df.rename(columns = {'Unnamed: 6':'Residential'}, inplace = True)\n",
    "        df['Residential'] = df.Residential.apply(float)\n",
    "        dfs2003[0] = pd.DataFrame(round(df.groupby('State')['Residential'].mean(), 2))\n",
    "        dfs2003[0].reset_index(inplace=True)\n",
    "    elif df is p2003Ind:\n",
    "        df.rename(columns = {'Unnamed: 6':'Industrial'}, inplace = True)\n",
    "        df['Industrial'] = df.Industrial.apply(float)\n",
    "        dfs2003[1] = pd.DataFrame(round(df.groupby('State')['Industrial'].mean(), 2))\n",
    "        dfs2003[1].reset_index(inplace=True)\n",
    "    elif df is p2003Com:\n",
    "        df.rename(columns = {'Unnamed: 6':'Commercial'}, inplace = True)\n",
    "        df['Commercial'] = df.Commercial.apply(float)\n",
    "        dfs2003[2] = pd.DataFrame(round(df.groupby('State')['Commercial'].mean(), 2))\n",
    "        dfs2003[2].reset_index(inplace=True)\n",
    "\n",
    "# Changing datatypes and adding inflation adjustments\n",
    "p2003 = dfs2003[0]\n",
    "p2003['Commercial'] = dfs2003[2]['Commercial']\n",
    "p2003['Industrial'] = dfs2003[1]['Industrial']\n",
    "p2003['Year'] = '2003'\n",
    "usline = {'State': 'US', 'Residential': 0, 'Commercial': 0, 'Industrial': 0, 'Year': '2003'}\n",
    "usline = pd.DataFrame(data = usline, index = [0])\n",
    "usline['Residential'] = round(p2003['Residential'].mean(), 2)\n",
    "usline['Commercial'] = round(p2003['Commercial'].mean(), 2)\n",
    "usline['Industrial'] = round(p2003['Industrial'].mean(), 2)\n",
    "p2003 = pd.concat([p2003, usline])\n",
    "p2003.set_index('Year', inplace = True)\n",
    "p2003['CPI'] = headline_cpi[9]\n",
    "p2003['Residential_adj'] = round(p2003['Residential'] / (p2003['CPI'] / 100), 2)\n",
    "p2003['Commercial_adj'] = round(p2003['Commercial'] / (p2003['CPI'] / 100), 2)\n",
    "p2003['Industrial_adj'] = round(p2003['Industrial'] / (p2003['CPI'] / 100), 2)\n",
    "p2003['Core_CPI'] = core_cpi[9]\n",
    "\n",
    "# creating dictionary of dataframes. State as key.\n",
    "p2003_dict = {}\n",
    "for state in list(p2003['State']):\n",
    "    p2003_dict[state] = p2003[p2003['State'] == state]\n",
    "    p2003_dict[state].drop(columns = 'State', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "718c1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "#p2003_dict['US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e01fec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for standardizing format of each dataframe.\n",
    "# Renamed columns, removed null values, removed transportation pricing as their were signicant quantities of null values\n",
    "# Added a column with year to each dataframe for organization later on\n",
    "# Concatenated all price dataframes years 2004 - 2022\n",
    "# Restructured the price data for consistency with generation data, a dictionary with dataframes by state\n",
    "\n",
    "def reading_prices_1(dfs):\n",
    "# Renaming and standardizing format\n",
    "    for df in dfs:\n",
    "        df.rename(columns={df.columns[0]:'State', 'Unnamed: 1':'Residential','Unnamed: 2':'Commercial',\n",
    "                           'Unnamed: 3':'Industrial','Unnamed: 4':'Transportation'}, inplace = True)\n",
    "        df.drop(columns = ['Unnamed: 5', 'Transportation'], inplace = True)\n",
    "        df.dropna(axis = 'columns', how = 'all', inplace = True)        \n",
    "        df.dropna(inplace = True)\n",
    "        df.reset_index(drop = True, inplace = True)\n",
    "        df.drop(0 , axis = 0, inplace = True)\n",
    "        df.reset_index(drop = True, inplace = True)       \n",
    "        df['State'] = df['State'].str.strip()\n",
    "        df.replace({\"State\": abbrev_dict}, inplace = True)\n",
    "# Year will later serve as index    \n",
    "        if df is p2022:\n",
    "            df['Year'] = '2022'\n",
    "        elif df is p2021:\n",
    "            df['Year'] = '2021'\n",
    "        elif df is p2020:\n",
    "            df['Year'] = '2020'\n",
    "        elif df is p2019:\n",
    "            df['Year'] = '2019'\n",
    "        elif df is p2018:\n",
    "            df['Year'] = '2018'\n",
    "        elif df is p2017:\n",
    "            df['Year'] = '2017'\n",
    "        elif df is p2016:\n",
    "            df['Year'] = '2016'\n",
    "        elif df is p2015:\n",
    "            df['Year'] = '2015'\n",
    "        elif df is p2014:\n",
    "            df['Year'] = '2014'\n",
    "        elif df is p2013:\n",
    "            df['Year'] = '2013'\n",
    "        elif df is p2012:\n",
    "            df['Year'] = '2012'\n",
    "        elif df is p2011:\n",
    "            df['Year'] = '2011'\n",
    "        elif df is p2010:\n",
    "            df['Year'] = '2010'\n",
    "        elif df is p2009:\n",
    "            df['Year'] = '2009'\n",
    "        elif df is p2008:\n",
    "            df['Year'] = '2008'\n",
    "        elif df is p2007:\n",
    "            df['Year'] = '2007'\n",
    "        elif df is p2006:\n",
    "            df['Year'] = '2006'\n",
    "        elif df is p2005:\n",
    "            df['Year'] = '2005'\n",
    "        elif df is p2004:\n",
    "            df['Year'] = '2004'\n",
    "# Creating dictionary of datafranes with state as key to be concatenated            \n",
    "    prices = pd.concat(dfs)\n",
    "    for state in set(prices['State']):\n",
    "        state_prices[state] = prices[prices['State'] == state]\n",
    "        state_prices[state].set_index('Year', inplace = True)\n",
    "        state_prices[state].columns.name = state\n",
    "        state_prices[state].drop(columns = 'State', inplace = True)\n",
    "        state_prices[state]['Residential'] = state_prices[state].Residential.apply(float)\n",
    "        state_prices[state]['Commercial'] = state_prices[state].Commercial.apply(float)\n",
    "        state_prices[state]['Industrial'] = state_prices[state].Industrial.apply(float)\n",
    "        state_prices[state] = state_prices[state][::-1]\n",
    "        state_prices[state]['CPI'] = headline_cpi[10::]\n",
    "        state_prices[state]['Residential_adj'] = round(state_prices[state]['Residential'] / (state_prices[state]['CPI'] / 100), 2)\n",
    "        state_prices[state]['Commercial_adj'] = round(state_prices[state]['Commercial'] / (state_prices[state]['CPI'] / 100), 2)\n",
    "        state_prices[state]['Industrial_adj'] = round(state_prices[state]['Industrial'] / (state_prices[state]['CPI'] / 100), 2)\n",
    "        state_prices[state]['Core_CPI'] = core_cpi[10::]\n",
    "        \n",
    "# Dropping regional data to add back once generation data can be formatted to accept\n",
    "    state_prices.pop('New England')\n",
    "    state_prices.pop('Middle Atlantic')\n",
    "    state_prices.pop('East North Central')\n",
    "    state_prices.pop('West North Central')\n",
    "    state_prices.pop('South Atlantic')\n",
    "    state_prices.pop('East South Central')\n",
    "    state_prices.pop('West South Central')\n",
    "    state_prices.pop('Mountain')\n",
    "    state_prices.pop('Pacific Contiguous')\n",
    "    state_prices.pop('Pacific Noncontiguous')\n",
    "# Concatenating all dictionaries of dataframes    \n",
    "    for state in state_prices:\n",
    "        state_pricing[state] = pd.concat([dfs01_94_dict[state], p2002_dict[state], p2003_dict[state], state_prices[state]])\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "599cb785",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reading_prices_1(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a6555415",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "#state_pricing['US']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
